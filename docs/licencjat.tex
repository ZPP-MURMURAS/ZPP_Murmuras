%
% Niniejszy plik stanowi przykład formatowania pracy magisterskiej na
% Wydziale MIM UW.  Szkielet użytych poleceń można wykorzystywać do
% woli, np. formatujac wlasna prace.
%
% Zawartosc merytoryczna stanowi oryginalnosiagniecie
% naukowosciowe Marcina Wolinskiego.  Wszelkie prawa zastrzeżone.
%
% Copyright (c) 2001 by Marcin Woliński <M.Wolinski@gust.org.pl>
% Poprawki spowodowane zmianami przepisów - Marcin Szczuka, 1.10.2004
% Poprawki spowodowane zmianami przepisow i ujednolicenie
% - Seweryn Karłowicz, 05.05.2006
% Dodanie wielu autorów i tłumaczenia na angielski - Kuba Pochrybniak, 29.11.2016

% dodaj opcję [licencjacka] dla pracy licencjackiej
% dodaj opcję [en] dla wersji angielskiej (mogą być obie: [licencjacka,en])
\documentclass[licencjacka,en]{pracamgr}
\usepackage{hyperref}  % Enables clickable links
\usepackage{xcolor}    % Allows hyperlink color customization
\usepackage{graphicx}
\usepackage{listings}

% Define JSON formatting style for listings
\lstdefinelanguage{json}{
    basicstyle=\ttfamily\small,
    numbers=left,
    numberstyle=\tiny,
    stepnumber=1,
    showstringspaces=false,
    breaklines=true,
    frame=single,
    backgroundcolor=\color{gray!10},
    keywordstyle=\color{blue},
    stringstyle=\color{red}
}

% Set hyperlink colors
\hypersetup{
    colorlinks=false,
    urlcolor=blue
}

% Dane magistranta:
\autori{Szymon Kozłowski}{448304}
\autorii{Gustaw Blachowski}{448194}
\autoriii{Kamil Dybek}{448224}
\autoriv{Natalia Junkiert}{448267}

\title{Using machine learning models for processing data presented to user by mobile devices.}

\tytulang{Using machine learning models for processing data presented to user by mobile devices.}
\titlepl{Wykorzystanie modeli uczenia maszynowego do procesowania danych zaprezentowanych użytkownikowi przez urządzenie mobilne.}

%kierunek:
% - matematyka, informacyka, ...
% - Mathematics, Computer Science, ...
\kierunek{Computer Science}

% informatyka - nie okreslamy zakresu (opcja zakomentowana)
% matematyka - zakres moze pozostac nieokreslony,
% a jesli ma byc okreslony dla pracy mgr,
% to przyjmuje jedna z wartosci:
% {metod matematycznych w finansach}
% {metod matematycznych w ubezpieczeniach}
% {matematyki stosowanej}
% {nauczania matematyki}
% Dla pracy licencjackiej mamy natomiast
% mozliwosc wpisania takiej wartosci zakresu:
% {Jednoczesnych Studiow Ekonomiczno--Matematycznych}

% \zakres{Tu wpisac, jesli trzeba, jedna z opcji podanych wyzej}

% Praca wykonana pod kierunkiem:
% (podać tytuł/stopień imię i nazwisko opiekuna
% Instytut
% ew. Wydział ew. Uczelnia (jeżeli nie MIM UW))
\opiekun{Jacek Sroka PhD\\
  Institute of Informatics\\
  }

% miesiąc i~rok:
\date{\today}

%Podać dziedzinę wg klasyfikacji Socrates-Erasmus:
\dziedzina{
%11.0 Matematyka, Informatyka:\\
%11.1 Matematyka\\
%11.2 Statystyka\\
%11.3 Informatyka\\
11.4 Artificial Intelligence\\
%11.5 Nauki aktuarialne\\
%11.9 Inne nauki matematyczne i informatyczne
}

%Klasyfikacja tematyczna wedlug AMS (matematyka) lub ACM (informatyka)
\klasyfikacja{
  I.2.7: Natural Language Processing\\
  H.3.3: Information Search and Retrieval}

% Słowa kluczowe:
\keywords{LLM, NLP, BERT, Android, Edge-device, Fine-Tuning}

% Tu jest dobre miejsce na Twoje własne makra i~środowiska:
\newtheorem{defi}{Definicja}[section]

% koniec definicji

\begin{document}

\maketitle

%tu idzie streszczenie na strone poczatkowa
\begin{abstract}
In an era of rapidly evolving digital applications, traditional scraping techniques face increasing challenges in maintaining reliable data collection pipelines. Commissioned by Murmuras, a company specializing in commercial and scientific data analysis, this project presents a novel approach to processing phone screen content, such as displayed social media posts and website advertisements. Our solution leverages Large Language Models (LLMs) running locally on the user's device to handle diverse data formats while ensuring that sensitive information remains protected. The primary application explored in this study is the extraction of discount coupons, demonstrating the feasibility of our method in identifying and structuring valuable content from varying digital sources. Furthermore, the system is designed to be easily adaptable to other use cases, such as analyzing users' political views. Additionally we explore usage of non-LLM models for the defined task. The results highlight the potential of LLM-driven content analysis as an alternative to conventional scraping techniques.
\raggedright
\end{abstract}

\tableofcontents
\listoffigures
\listoftables

\chapter{Introduction}
\section{Digital coupon definition and related research methodologies}
\subsection{The definition of a coupon}
A coupon is a physical piece of paper or digital voucher that can be redeemed for a financial discount when purchasing a product \cite{coupon_definition}. A coupon is characterized by a name, expiration date, and a discount type, e.g. '20\% off', 'buy 1 get 1 free', etc., however, not every coupon contains each of these features. Furthermore, coupons may contain numerous other features such as images and eligibility requirements. Henceforth, the term 'coupon' will refer exclusively to a digital coupon. The term 'conventional coupon' will refer to the traditional physical coupon. The examples of digital coupons encountered in mobile applications are presented in \ref{fig:example_coupons}

\begin{figure}[h]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{coupon1.jpg}
        \caption{The example coupon from fast-food restaurants chain mobile application}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{coupon2.jpg}
        \caption{The example coupon from grocery store mobile application}
    \end{minipage}
    \caption{The example digital coupons}
    \label{fig:example_coupons}
\end{figure}


\subsection{Our data model of digital coupon}
\label{sec:coupon_model}
In the following research we model a digital coupon as a collection of named fields:
\begin{enumerate}
    \item \textit{product\_name}: the name of the product
    \item \textit{valid\_unitl}: the text representing the date of coupon expiration
    \item \textit{discount\_text}: the text representing the discount offered to the user
    \item \textit{activated}: either true or false, indicates whether the coupon has been activated
\end{enumerate}
We will allow for special \textit{null} value in the above fields in case no data is available.

An example of a digital coupon represented in JSON format is shown below:

\begin{lstlisting}[language=json, caption={Example of a digital coupon in JSON format}, label={lst:coupon_example}]
{
    "product_name": "Shampoo X",
    "valid_unitl": "2025-06-30",
    "discount_text": "20% OFF",
    "activated": true
}
\end{lstlisting}

\subsection{Collection of Statistics Related to Digital Coupons}
Given the significance of digital coupons in contemporary marketing strategies \cite{targeted_reminders}, analyzing their lifecycle is essential. To facilitate such analyses, researchers collect various statistical metrics, including the fraction of redeemed coupons among all distributed coupons referred henceforth as redemption rate \cite{danaher2015} and customer engagement \cite{jayadharshini2023}, while also assessing their impact on sales performance \cite{jayadharshini2023}.

\subsubsection{Redemption Rate}
The measurement of coupon redemption rates is primarily based on either survey data \cite{nayal2021} or controlled experimental studies \cite{danaher2015}. However, the company Murmuras \cite{murmuras} has introduced an alternative approach that enables the direct collection of coupon-related data from users' devices. This method utilizes a screen content scraping tool installed on the devices. Additionally, the tool has the ability to record user's actions.  Having access to all the user's interactions and visual changes in the layout, it is possible to detect the coupon redemption. This allows for large-scale data acquisition while reducing the costs associated with traditional survey-based methods.

\subsubsection{Customer Engagement and Impact on Sales}

Customer engagement metrics, such as conversion rates and the effect of e-coupon issuance on sales, can potentially be measured using statistical analysis tools operating on the seller's website~\cite{seo2023}. The conversion rate is typically derived by tracking visitor activity, while the impact on sales is estimated by correlating the updated conversion rate with the frequency of coupon issuance.

Although this approach provides valuable insights, it relies on direct collaboration with the coupon issuer and is constrained to a single webpage. Consequently, it is not applicable to our study, as we aim to analyze arbitrary mobile applications with diverse coupon designs.

\section{Project background and motivation}
With the rapid advancement of information technology, the Internet has become one of the most crucial facets for many businesses to perform marketing activities \cite{design_of_coupons}. One of the key marketing tools in business-to-consumer (B2C) e-commerce is the digital coupon (also referred to as an electronic coupon) \cite{targeted_reminders}. In comparison to paper coupons, digital coupons are characterized by their wide reach, rapid distribution, and low spread costs. Furthermore, a key advantage of digital coupons is their ability to facilitate targeted marketing by offering personalized discounts to different customers, thereby increasing sales \cite{design_of_coupons}. To maximize the benefits of digital coupons, it is essential for businesses to assess the effectiveness of their coupon campaigns, evaluate their reach, and analyze their competitors’ strategies. By tracking key performance metrics such as redemption rates, customer engagement, and sales impact, businesses can refine their marketing approaches to optimize results. Additionally, studying competitors' digital coupon strategies enables businesses to identify market trends, adjust their promotional tactics, and maintain a competitive edge in the evolving digital marketplace.

Large Language Models (LLMs) have become a fundamental technique in contemporary machine learning, replacing previously utilized recurrent neural network (RNN) architectures in the field of natural language processing (NLP) \cite{li2024}. Subsequent research has demonstrated their applicability to structured input data \cite{sui2024}. Additionally, there have been efforts to integrate these models into web scraping pipelines \cite{scapegraph_repo}.

Recent statistics underscore the significance of mobile devices in the domain of coupon distribution. For example, studies have shown that over 90\% of digital coupon users access their vouchers via smartphones \cite{emarketer_coupon_stats}, and similar figures are reported by other industry sources \cite{coupon_stats_2}. This high rate of mobile usage creates a pressing need for coupon analysis tools that are optimized for mobile platforms, ensuring that consumers receive timely and personalized offers regardless of their location or device.

In light of these trends, the company Murmuras has tasked us with developing a solution based on a machine learning model that can be deployed as a mobile application. This model will process input representing the user's onscreen view and extract digital coupons along with their relevant data. This solution must be capable of running locally on the device, ensuring efficient processing without relying on external servers. By leveraging advanced machine learning techniques, the app will handle the diverse formats and layouts of digital coupons, thereby facilitating the collection of data regarding coupons.

\section{Problem Statement}

The objective of this work is to extract coupons visible to the user from the content displayed on a mobile device screen. The extracted coupons should be represented as a JSON list, with each entry conforming to the format specified in Section~\ref{sec:coupon_model}.

The screen content is provided in the form of a \texttt{.CSV} file, which encodes an XML tree structure representing the underlying screen layout. Each row in this file corresponds to a single view element within the screen hierarchy~\cite{android_view}. The dataset includes at least the following attributes:

\begin{enumerate}
    \item \textbf{view\_depth}: The depth of the view within the XML tree hierarchy.
    \item \textbf{text}: The textual content displayed to the user within the view.
    \item \textbf{id}: A unique identifier for a screen sample. Each sample consists of a set of views observed either simultaneously or in directly consecutive snapshots.
    \item \textbf{time}: The timestamp indicating when the view was recorded.
    \item \textbf{view\_id}: The unique identifier assigned to the view by the Android API.
\end{enumerate}

An example of the dataset to illustrate described format is provided in Table~\ref{tab:dataset_example}.

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        \textbf{view\_depth} & \textbf{text} & \textbf{id} & \textbf{time} & \textbf{view\_id} \\
        \hline
        2 & "50\% OFF" & 101 & 12:30:15 & \texttt{com.example.app:id/discount\_label} \\
        3 & "Buy 1 Get 1 Free" & 101 & 12:30:15 & \texttt{com.example.app:id/promo\_banner} \\
        2 & "Limited Offer" & 102 & 12:31:05 & \texttt{com.example.app:id/offer\_text} \\
        \hline
    \end{tabular}
    \caption{Example of dataset format representing screen content.}
    \label{tab:dataset_example}
\end{table}

Additional requirement is that the screen content processing will be performed exclusively on the end device to mitigate potential privacy concerns.

\section{Project goals}
\begin{enumerate}
    \item A tool to process the data extracted from the device into a format suitable for use by the model.
    \item A machine learning tool for extracting the data that is of interest to us, such as the coupon name, expiration dates, prices, etc. The model should be capable of handling various coupon formats and layouts with high accuracy.
    \item An optional tool for post-processing the output data from the tool mentioned in the previous point into a common format.
    \item An application that runs the above three tools on a mobile device. (Optional)
    \item A key requirement is that the machine learning model must be deployable on the mobile device itself to guarantee data privacy.
\end{enumerate}

\section{Potential applications of the project}
\subsection{Assessing coupon effectiveness}
The access to the content of mobile device screen allows us to list all the coupons seen by the user. Additionally, as we will retrieve information about coupon activation status, there will be possibility to track coupon redemptions by comparing the coupons models \textit{active} field.

Given that, our solution will aid businesses in analyzing consumer behavior and optimizing their marketing strategies. By facilitating the collection of data on coupon characteristics and their redemption rates, businesses will be able to assess the effectiveness of their coupon campaigns—determining whether they achieve the desired results. Additionally, large-scale analysis of coupon data can reveal valuable insights into purchasing patterns, preferred discount types, and the most appealing products or services.

\subsection{Market analysis and competitor monitoring}
The machine learning is proven to be a useful tool in the field of market competitors analysis but it requires significant amounts of data\cite{competitor_tariffs}.
The aforementioned gathering of data about displayed coupons can also be utilized in further monitoring of competitors' coupon strategies, their effectiveness, and whether they provide better discounts. Using machine learning to identify and analyze competitors' strategies is more cost-effective compared to exhaustive web scraping or mystery shopping \cite{competitor_tariffs}. This will enable businesses to make better informed decisions about their own marketing campaigns and provide a comprehensive understanding of the competitive landscape.

\chapter{Machine learning and the dangers associated with it}
Note: this chapter is a work in progress, bullet points aim to provide guidance when writing this section

(1) What is the difference between machine learning, artificial intelligence, and deep learning? \\
(1a) Provide the definitions/a brief explanation of each of the above.\\
(1b) Explain what a benchmark is and what it is used for. \\

\subsection{Benchmark}
Benchmarking is the process of running a set of, among others, computer programs against a set of tests to assess their relative performance or precision \cite{benchmark}.

(2) Understanding ML models \\
(2a) Explain what a model is \\
(2b) Explain how a model works, how it is trained, datasets, linear regression, supervised vs unsupervised learning (?), federated learning (?), computer vision (?) \\
(2c) What is quantization and why it is this of interest to us \\

(3) What is NLP \\
(3a) Explain what NLP is and why it is of interest to us for this project \\
(3b) BERT, Llama, ChatGPT and other models (briefly explain their differences, advantages and disadvantages, paramters, memory usage (?)) \\

(4) Should we be scared of AI? \\
(4a) https://www.youtube.com/watch?v=yh1pF1zaauc. (from our mentor) \\
(4b) Privacy and ethics of data collection and processing (present the problem, why people are concerned about this, then later on in the document we say that we resolved this issue because we are processing the data locally etc) \\
(4c) Adversarial attacks (I'm not sure this is particularly relevant to our project but it mught be worth mentioning) \\
(4e) Accuracy concerns, how can we be sure that our model is correct? Lack of human oversight \\
(4f) Environmental concerns
// HF tutorial: env concerns => fine tune not training



\chapter{Overview of Existing Solutions}

To the best of our knowledge, at the time of this project's commissioning, no publicly available solutions directly addressed this problem. The most comparable approaches involve existing multimodal models. While widely used models such as ChatGPT and Gemini provide general data extraction capabilities~\cite{brinkmann2023}, they are unsuitable for our task due to their substantial computational requirements. A key limitation of these models is their large size—for example, GPT-3 consists of 175 billion parameters\cite{chatgpt_params}—rendering them impractical for deployment on mobile devices~\cite{LinguaLinked}.

Alternatively, computer vision models can be used to extract text and bounding boxes from screen images. Microsoft’s OmniParser~\cite{omniparser_intro}, for instance, has demonstrated strong performance on the ScreenSpot dataset~\cite{omniparser_intro, cheng2024}. However, the challenge of organizing extracted text into structured coupon data renders this approach unsuitable for our study. Furthermore, our experiments with running OmniParser locally on example images indicate that it relies on CUDA technology, making it impractical for deployment on mobile devices.

\section{Murmuras' existing solution}
Murmuras' current approach relies on a set of fixed scrapping programms tailored to specific layouts from limited set of applications, making it inflexible and expansive to generalize across diverse coupon formats. This lack of adaptability limits its usefulness in real-world scenarios where coupon structures vary widely. Since our goal is to develop a solution that is easily adaptable for processing diverse mobile content, this method is not well-suited for our needs.

In contrast, Murmuras' most-recent proof of concept involves wrapping the \texttt{CSV} data with a prompt that instructs the model and sending it to GPT-4o-mini. This approach leverages an LLM to interpret the data to extract relevant coupon details. However, the reliance on an external server means the solution does not run locally on the mobile device, leading to potential privacy concerns, latency issues, and a dependence on internet connectivity.

\section{Scapegraph AI}
ScrapeGraphAI is an open-source library that streamlines data extraction from websites and local documents by utilizing LLMs and graph logic to construct scraping pipelines \cite{scapegraph_repo}. The library supports integration with various LLMs, including local models through the use of Ollama \cite{ollama_repo} \cite{scapegraph_usage}.

However, Scrapepraph AI provides only Python and Node.js SDKs \cite{scapegraph_sdks}, which could prove to be an issue with regard to mobile deployment, because neither Python nor Node.js is natively supported on iOS or Android \cite{android_dev_site} \cite{ios_dev_site}.

Moreover, due to mobile devices typically having limited processing power and memory compared to desktop computers or servers \cite{mobile_resources}, we cannot solely rely on the size of the model in order to improve performance. We believe that through fine-tuning LLMs, we are able to develop tools that are far more viable for edge device usage.


\chapter{Description of datasets} \label{chap:datasets}
\section{Raw datasets} 
We received datasets corresponding to six different mobile applications: Edeka, Rossmann, DM, Rewe, Lidl, and Penny. Each dataset was provided as a CSV file containing XML representations of the data captured from the device interface during user interactions with the respective app. The selection of these applications, as well as the data collection and processing procedures, were carried out by Murmuras.

For each application, two key files were provided: the \textit{content\_generic} CSV file, which contains screen-captured data in XML format (see ~\ref{tab:coupons_rev_2_content}), and the \textit{coupons} CSV file, which serves as the ground truth (see ~\ref{tab:coupons_rev_2}). The latter includes the coupons that our solution is expected to identify, along with the specific information that should be extracted from them. We have removed unnecessary columns from the datasets.


\begin{table}[ht]
\centering

\begin{tabular}{|p{0.9\textwidth}|}
\hline
\textbf{content\_full} \\
\hline
[Treuepunkte, 10\% Rabatt*, auf alle REWE Bio + vegan Produkte!, 
Kaufe mind. 2 Produkte., Gültig bis 14.01.2024, Coupon aktivieren] \\
\hline
\end{tabular}

\vspace{1em}

\begin{tabular}{|l|l|l|}
\hline
\textbf{discount\_text} & \textbf{activation\_text} & \textbf{validity\_text} \\
\hline
10\% Rabatt* & Coupon aktivieren & Gültig bis 14.01.2024 \\
\hline
\end{tabular}

\vspace{1em}

\begin{tabular}{|l|l|l|}
\hline
\textbf{product\_text} & \textbf{discount\_details} & \textbf{aggregation} \\
\hline
auf alle REWE Bio + vegan Produkte! & Kaufe mind. 2 Produkte. & 1704181455161 \\
\hline
\end{tabular}

\caption{Cleaned coupon file format (ground truth)}
\label{tab:coupons_rev_2}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{view\_id} & \textbf{text} & \textbf{view\_depth} & \textbf{aggregation} \\
\hline
de.rewe.app.mobile:id/action\_bar\_root &  & 3 & 1704181453677 \\
\hline
\end{tabular}
\caption{Screen content file format}
\label{tab:coupons_rev_2_content}
\end{table}




\section{Dataset Formats}
We preprocess the raw data to ensure it is structured in a manner that can be effectively utilized by the models. The results of this preprocessing are described in the following sections.

\subsection{BERT Datasets}
The BERT models accept two dataset formats during the coupon selection phase in which the model identifies where a coupon begins and ends:

\begin{enumerate}
    \item \textbf{Plain format:} This format consists of raw, concatenated texts extracted from the `text` field in the \texttt{content\_generic} CSV file.
    \item \textbf{XML Tree format:} This format encodes the data from the \texttt{content\_generic} CSV file into an XML tree structure, which is then represented in JSON format, as shown in ~\ref{fig:json_example_xml_tree}.
\end{enumerate}

On the other hand, the format depicted in Table~\ref{tab:coupon_extraction_example} is used during the coupon extraction phase, wherein relevant coupon information is tagged with structured labels. Each label corresponds to a specific type of information extracted from the screen text:

\begin{itemize}
    \item \textbf{0} – Generic or descriptive text
    \item \textbf{1} – Product or item the coupon is about
    \item \textbf{3} – Coupon activation phrase
    \item \textbf{5} – Validity date
    \item \textbf{7} – Discount or offer
\end{itemize}

\begin{table}[h]
\centering
\begin{tabular}{|p{8cm}|p{2cm}|}
\hline
\textbf{Text} & \textbf{Label} \\
\hline
tiefgefroren je 410--460 g Packung (1kg= 6.50/7.29) & 0 \\
\hline
Coupon aktivieren & 3 \\
\hline
Gültig bis 07.01.2024 & 5 \\
\hline
Knaller 2.99 € statt Aktionspreis 3.33 €!* & 7 \\
\hline
Gustavo Gusto Pizza Margherita oder Salame & 1 \\
\hline
\end{tabular}
\caption{Example of text and corresponding labels in the coupon information extraction dataset.}
\label{tab:coupon_extraction_example}
\end{table}





\begin{figure}[ht]
\centering
\begin{tcolorbox}[sharp corners, boxrule=0.5mm, colframe=black, colback=white, coltitle=black, width=0.9\textwidth] 
\begin{BVerbatim}
{
   "text": "text field content",
   "children": {
       "child1_view_id": ...,
       "child2_view_id": ...,
       ...
   }
}
\end{BVerbatim}
\end{tcolorbox}
\caption{Sample JSON Format for BERT Dataset}
\label{fig:json_example_xml_tree}
\end{figure}

\subsection{Llama Datasets}\label{llamaDsDesc}
The Llama models take in the following dataset formats:

\begin{enumerate}
    \item \textbf{one\_input\_multiple\_outputs\_wrequest}: the dataset includes a task description to the Llama model.
    \item \textbf{one\_input\_multiple\_outputs\_wthrequest}: the dataset does not include a task description.
\end{enumerate}

The input format for the Llama models is as in ~\ref{fig:llama_ds_w} and ~\ref{fig:llama_ds_wth}.

\begin{figure}[ht]
\centering
\begin{tcolorbox}[sharp corners, boxrule=0.5mm, colframe=black, colback=white, coltitle=black, width=0.9\textwidth] 
\begin{BVerbatim}
{
   You are provided with text representing contents of the 
   phone screen. Your task is to extract information about 
   coupons from the text. The information should include 
   the product name, the validity text, the discount text 
   and the activation text.       
   ### Input: {screen content data}
   ### Response: {coupons in a form of JSON array}
}
\end{BVerbatim}
\end{tcolorbox}
\caption{Llama input format with a task description}
\label{fig:llama_ds_w}
\end{figure}

\begin{figure}[ht]
\centering
\begin{tcolorbox}[sharp corners, boxrule=0.5mm, colframe=black, colback=white, coltitle=black, width=0.9\textwidth] 
\begin{BVerbatim}
{
   ## Input: {screen content data}
   ## Response: {coupons in a form of JSON array}
}
\end{BVerbatim}
\end{tcolorbox}
\caption{Llama input format without a prompt}
\label{fig:llama_ds_wth}
\end{figure}

\subsection{Dataset statistics}
This section provides an overview of the dataset statistics along with a brief analysis.

% może z tego zrobić appendix? 
\begin{table}[h!]
\centering
\begin{tabular}{|l|l|r|r|}
\hline
\textbf{Application} & \textbf{Split} & \textbf{Bytes} & \textbf{Examples} \\
\hline
Edeka     & Train & 632,413  & 298 \\
          & Test  & 208,987  & 75 \\
DM        & Train & 6,863,888 & 2,317 \\
          & Test  & 1,734,466 & 580 \\
Lidl      & Train & 8,160,797 & 3,180 \\
          & Test  & 2,194,200 & 796 \\
Penny     & Train & 51,263   & 79 \\
          & Test  & 11,724   & 20 \\
Rewe      & Train & 4,210,545 & 1,724 \\
          & Test  & 1,051,741 & 432 \\
Rossmann  & Train & 3,806,354 & 1,476 \\
          & Test  & 942,792  & 370 \\
\hline
\end{tabular}
\caption{Dataset sizes and example counts per application and split for the coupon selection stage.}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{|l|l|r|r|}
\hline
\textbf{Application} & \textbf{Split} & \textbf{Examples} & \textbf{Bytes} \\
\hline
Penny     & Train & 76  & 77,006 \\
          & Test  & 20  & 15,834 \\
Lidl      & Train & 3,183 & 10,186,116 \\
          & Test  & 796  & 2,094,306 \\
Rewe      & Train & 1,728 & 5,811,132 \\
          & Test  & 432  & 2,223,958 \\
Edeka     & Train & 295  & 762,506 \\
          & Test  & 74   & 118,532 \\
DM        & Train & 2,279 & 6,720,006 \\
          & Test  & 570  & 2,739,686 \\
Rossmann  & Train & 1,476 & 3,883,376 \\
          & Test  & 370  & 1,220,512 \\
\hline
\end{tabular}
\caption{Dataset size and example counts per application and split for the Llama models}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{|l|l|r|r|}
\hline
\textbf{Application} & \textbf{Split} & \textbf{Examples} & \textbf{Bytes} \\
\hline
Edeka     & Train & 52  & 7,683 \\
          & Test  & 14  & 1,345 \\
DM        & Train & 748 & 106,284 \\
          & Test  & 187 & 22,945 \\
Lidl      & Train & 1,773 & 223,428 \\
          & Test  & 444  & 55,066 \\
Penny     & Train & 38  & 3,635 \\
          & Test  & 10  & 823 \\
Rewe      & Train & 668 & 126,634 \\
          & Test  & 167 & 31,203 \\
Rossmann  & Train & 366 & 57,919 \\
          & Test  & 92  & 14,303 \\
\hline
\end{tabular}
\caption{Dataset size and example counts per application and split for the BERT models}
\end{table}

\begin{table}[h!]
\raggedright
\setlength{\tabcolsep}{4pt} 
\small % or \footnotesize or \scriptsize
\begin{tabular}{|l|r|r|r|r|r|}
\hline
\textbf{Application} & \textbf{Discount Text} & \textbf{Product Name} & \textbf{Valid Until} & \textbf{Activation Text} & \textbf{Missing (\%)} \\
\hline
DM        & 1,497 & 1,614 & 1,530 & 2,095 & 50.15\% \\
Edeka     & 58    & 17    & 338   & 336   & 92.68\% \\
Lidl      & 235   & 104   & 242   & 258   & 3.01\% \\
Penny     & 0     & 0     & 0     & 36    & 53.73\% \\
Rewe      & 45    & 63    & 20    & 3     & 0.81\% \\
Rossmann  & 0     & 0     & 7     & 18    & 0.68\% \\
\hline
\end{tabular}
\caption{Missing feature counts and percentage of coupons missing at least one feature per company (test and train sets combined)}
\label{tab:missing_coupons}
\end{table}

As seen in ~\ref{tab:missing_coupons}, 92.68\% of Edeka coupons and ~50\% of DM and Penny coupons, are missing at least one feature. This missing data in coupon features presents clear challenges for building reliable extraction models as it makes it difficult for models to learn consistent patterns across sources.

A major consequence is lower recall. When key fields such as discount text, product names, or validity dates are missing during training, the model lacks enough examples to learn how to identify them reliably. This often results in false negatives, especially for sources with frequent data gaps, while performance tends to improve on more complete datasets.

This presents evaluation challenges, as we have to account for the possibility that some ground truth coupons are unannotated. As a result, a model may correctly identify a valid instance but be penalized as if it were a false positive or false negative, which can distort metrics like precision, recall, and F1-score.


% \chapter{Technologies}
% \chapter{Architecture design}
% \chapter{Performance}
% \chapter{Possible extensions}
% \chapter{Summary}
% \chapter{Charts}



\begin{thebibliography}{99}

\addcontentsline{toc}{chapter}{Bibliography}

\bibitem{murmuras}
\textit{Murmuras website}.
\url{https://murmuras.com/}.
[Accessed 2025-02-11].

\bibitem{coupon_definition}
\textit{Britannica Dictionary definition of COUPON}.
\url{https://www.britannica.com/dictionary/coupon}.
[Accessed 2025-02-03].

\bibitem{benchmark}
\textit{Computer Benchmark}.
\url{https://bhatabhishek-ylp.medium.com/benchmarking-in-computer-c6d364681512}.
[Accessed 2025-02-03].

\bibitem{design_of_coupons}
Xiong Keyi, Yang Wensheng
\textit{Research on the Design of E-coupons for Directional Marketing of Two Businesses in Competitive Environment}.
\url{https://www.sciencepublishinggroup.com/article/10.11648/j.ijefm.20200801.16}.
[Accessed 2025-02-04].

\bibitem{targeted_reminders}
Li Li, et. al.
\textit{Targeted reminders of electronic coupons: using predictive analytics to facilitate coupon marketing}.
\url{https://link.springer.com/article/10.1007/s10660-020-09405-4}.
[Accessed 2025-02-04].

\bibitem{competitor_tariffs}
Bernhard König, et. al.
\textit{Analysing competitor tariffs with machine learning}.
\url{https://www.milliman.com/en/insight/analysing-competitor-tariffs-with-machine-learning}.
[Accessed 2025-02-04].

\bibitem{ml_general}
Iqbal H. Sarker
\textit{Machine Learning: Algorithms, Real-World Applications and Research Directions}.
\url{https://link.springer.com/article/10.1007/s42979-021-00592-x}.
[Accessed 2025-02-05].

\bibitem{emarketer_coupon_stats}
Sara Lebow
\textit{How consumers access digital coupons}.
\url{https://www.emarketer.com/content/how-consumers-access-digital-coupons}.
[Accessed 2025-02-05].

\bibitem{coupon_stats_2}
\textit{Unveiling IT Coupons Trends and Statistics}.
\url{https://www.go-globe.com/unveiling-it-coupons-trends-statistics/}.
[Accessed 2025-02-05].

\bibitem{chatgpt_params}
\textit{Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish
Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen
Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M.
Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen,
Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark,
Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and
Dario Amodei. Language models are few-shot learners, 2020}
// Would be great to get the link and change this into APA

\bibitem{scapegraph_intro}
Satyam Tripathi
\textit{ScrapeGraphAI Tutorial - Getting Started with LLMs Web Scraping}
\url{https://scrapingant.com/blog/scrapegraphai-llms-web-scraping}

\bibitem{omniparser_intro}
\textit{Yadong Lu, Jianwei Yang, Yelong Shen, and Ahmed Awadallah. Omni-
parser for pure vision based gui agent, 2024.}

\bibitem{gh_issue_810_scapegraph}
\textit{Can not Set Model Tokens to Local Model with OpenAI API Format \#810}
\url{https://github.com/ScrapeGraphAI/Scrapegraph-ai/issues/810}

\bibitem{gh_issue_752_scapegraph}
\textit{Can't load tokenizer for 'gpt2' \#752}
\url{https://github.com/ScrapeGraphAI/Scrapegraph-ai/issues/752}

\bibitem{mobile_resources}
Xiang Li, et. al.
\textit{Large Language Models on Mobile Devices: Measurements, Analysis, and Insights}
\url{https://dl.acm.org/doi/10.1145/3662006.366205}

\bibitem{LinguaLinked}
Junchen Zhao, et. al.
\textit{LinguaLinked: A Distributed Large Language Model Inference System for Mobile Devices}
\url{https://arxiv.org/pdf/2312.00388}

\bibitem{sequence_matcher}
\textit{difflib — Helpers for computing deltas}
\url{https://docs.python.org/3/library/difflib.html}

\end{thebibliography}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% coding: latin-2
%%% End:
