\documentclass[12pt]{article}

\usepackage{hyperref}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\selectlanguage{polish}

\title{ZPP Murmuras - HLD}
\author{Gustaw Blachowski \and Szymon Kozłowski \and Natalia Junkiert \and Kamil Dybek}
\date{}

\begin{document}

\maketitle

\section*{Wprowadzenie}

Celem projektu jest stworzenie uniwersalnego rozwiązania do analizy danych tekstowych, który w przyszłości będzie można rozszerzyć na inne rodzaje danych zbieranych przez urządzenia mobilne, takie jak dane lokalizacyjne (GPS) czy dane multimedialne (zdjęcia, filmy, dźwięki). System ten ma umożliwić pozyskiwanie i analizę informacji dotyczących treści odbieranych i generowanych przez użytkowników, wspierając tym samym analizy o charakterze komercyjnym i społecznym. \\

Przykładowymi zastosowaniami systemu to (1) analiza danych o oglądanych przez użytkownika reklamach oraz (2) badanie poglądów politycznych i społecznych. \\

(1) System będzie umożliwiał zbieranie danych o wyświetlanych przez użytkownika reklamach oraz analizowanie tych danych z perspektywy strategii reklamowych i rynkowych. Dane takie jak liczba kliknięć i czas poświęcony na interakcję lub wyświetlanie reklam umożliwi ocenianie efektywności kampanii reklamowych oraz dostosowanie strategii marketingowych do preferencji użytkowników. Dzięki temu możliwe będzie lepsze targetowanie reklam, optymalizacja budżetów marketingowych oraz zwiększenie zaangażowania odbiorców poprzez prezentowanie bardziej trafnych i interesujących treści reklamowych. \\

(2) System będzie umożliwiał lokalną analizę danych prywatnych takich jak prywatne wiadomości użytkownika, dając unikalną możliwość zbierania wiarygodnych danych o poglądach politycznych i społecznych. Ze względu na wrażliwość takich informacji, dane takie będą musiały być z~dużą dokładnością anonimizowane, na przykład implementując rozwiązania z~zakresu \emph{differential privacy}.


\section*{Istniejące rozwiązania}

jakie już toole istnieją i jaką mają efektywność? murmuras ma jakiegoś wstępnego solva, napisać o jego limitacjach i co chcemy poprawić wględem ich solva


\section*{Zastosowania biznesowe}

We wprowadzeniu podane zostały przykłady zostosowań biznesowych tego systemu. W następującej sekcji zostanie to doprecyzowane.


\section*{Specyfikacja skończonego projektu}
wymagania klienta oraz jak planujemy to zaadresować

\section*{Wyzwania}
\subsection{Ograniczenia prawne}

\subsection{Zapewnianie prywatności użytkowników}
Zapewnienie prywatności danych prywatnych użytkowników poprzez \emph{differential privacy} oraz skuteczne rozróżnienie danych prywatnych od półprywatnych lub publicznych

\subsection{Wymagania sprzętowe}
Wymagania sprzętowe LLMów mogą okazać się zbyt duże na analizę zebranych danych w czasie rzeczywistym, zatem koniecznym może się okazać przetwarzanie danych w nocy.  

\subsection{Zaimplementowanie modelu spełniające wymagania}
Zapewnienie prywatności danych prywatnych użytkowników poprzez \emph{differential privacy} oraz skuteczne rozróżnienie danych prywatnych od półprywatnych lub publicznych.
Zaimplementowanie \emph{federated learning}, aby dotrenowywać model.
Zrozumienie kontekstu treści, wykrywając niuanse językowe oraz intencje autora.
Zapewnienie wysokiej jakości analizy danych oraz dokładne wyniki, szczególnie przy analizie niejednoznacznych bądź niepełnych danych.




















\section*{Propozycja rozwiązania}
\subsection*{Ogólny zarys}
Aplikacja mobilna zbierająca dane w urządzeniu i~douczająca lokalny modelklasyfikacyjny/rozpoznający interesujące nas sekcje.

\subsubsection*{Zbieranie widoków z~ekranu smartfonu}
\begin{itemize}
    \item Android Accessibility API - istniejące narzędzie wewnątrz firmy, wymagana integracja
    \item Maskowanie danych prywatnych - NER (Named Entity Recognition), modele językowe
\end{itemize}

\subsubsection*{Preprocessing widoków}
Standaryzacja danych umożliwiająca uczenie maszynowe na tych danych.

\subsubsection*{Przetwarzanie z~wykorzystaniem MLa}
\begin{itemize}
    \item Klasyfikacja sekcji - webscraping
    \item Wykorzystanie LLM (ewentualnie alternatywy) do pozyskania z~tekstu oznaczonych i~ustrukturyzowanych informacji
    \item Aktualizacja globalnego modelu - \emph{federated learning}
\end{itemize}

\section*{Rozwinięcie planu implementacji}

\subsection*{Aplikacja mobilna}
\begin{itemize}
    \item Zbieranie danych: TBD
\end{itemize}

\subsubsection*{Narzędzia}
\begin{itemize}
    \item Android Studio: \url{https://developer.android.com/studio}
    \item Android accessibility services: \url{https://developer.android.com/guide/topics/ui/accessibility/service}
    \item Wewnętrzny tool firmy: Android Accessibility API
\end{itemize}

\subsection*{Modele ML}

\subsubsection*{Use Cases}
\begin{itemize}
    \item Klasyfikacja
    \item Scraping
\end{itemize}

\subsubsection*{Architektury}
\begin{itemize}
    \item LLM (transformers): elastyczność, potencjalna multimodalność kosztem dużych wymagań sprzętowych
    \item RNN: lightweightowy, prosty w samodzielnej implementacji, mniejsza elastyczność
    \item Federated learning: rozproszenie procesu trenowania między urządzenia i synchronizowanie modeli co jakiś czas
\end{itemize}

\subsubsection*{Frameworki}
\begin{itemize}
    \item TensorFlow Federated: prosty flow od stworzenia modelu poprzez jego konwersję na TensorFlow Lite aż do deploymentu, ale nie wiadomo na ten moment, czy wspiera heterogeniczny FL.
    \item HeteroFL (licencja MIT): Framework pozwalający na Federated Learning przy heterogenicznych modelach lokalnych, co pozwoli na deployment rozwiązania na większej liczbie urządzeń.
\end{itemize}

\subsection*{Wyzwania}
\begin{itemize}
    \item Wymagania sprzętowe LLMów mogą okazać się zbyt duże na analizę zebranych danych w~czasie rzeczywistym - możliwe rozwiązanie: przetwarzanie danych w~nocy.
    \item Pozyskanie danych i~zasobów do trenowania modelu. Opracowanie algorytmu przetwarzającego dane zbierane na urządzeniach w~dowolnej sytuacji.
    \item Zapewnienie prywatności danych prywatnych użytkowników poprzez \emph{differential privacy} oraz skuteczne rozróżnienie danych prywatnych od półprywatnych lub publicznych.
    \item Zaimplementowanie \emph{federated learning}, aby dotrenowywać model.
    \item Zrozumienie kontekstu treści, wykrywając niuanse językowe oraz intencje autora.
    \item Zapewnienie wysokiej jakości analizy danych oraz dokładne wyniki, szczególnie przy analizie niejednoznacznych bądź niepełnych danych.
\end{itemize}

\section*{Kolejne kroki pracy}
\begin{itemize}
    \item Implementacja algorytmu standaryzacji danych: Dane które otrzymamy mają strukturę drzewiastą; trzeba te dane posegregować (np. ze względu na głębokość drzewa, ojców, etc.) i~ułożyć w~formę, którą łatwo będzie zaserwować modelowi do nauki.
    \item Prototyp możliwy do utworzenia poza urządzeniami docelowymi; pozyskanie danych treningowych - otrzymane od firmy, w~miarę możliwości samodzielnie wygenerowane.
    \item Wybór modelu: Interesują nas modele, które będziemy w~stanie uruchomić i~trenować na telefonie.
    \item Istniejący wewnątrz firmy prototyp korzysta z~prompt engineeringu w~Chat-GPT, ale jest to model zbyt duży i wymagający; jedną z~opcji jest model bez promptów, gdyż wpływają one negatywnie na wymagania modelu, bądź wyjście poza LLM.
    \item Chcemy, aby nasz model był kompatybilny z frameworkami Federated Learning, takimi jak TensorFlow oraz HeteroFL.
    \item Przetestujemy i~porównamy różne modele poza urządzeniem docelowym.
    \item Mamy dwie opcje odnośnie ternowania mocelu: trenować cały model lokalnie na telefonach, 
    dzięki czemu dane prywatne będą miały większy wpływ na wynik, albo wytrenować podstawowy model na serwerze i~dotrenowywać go na urządzeniach końcowych, co jest tańsze obliczeniowo.
    \item Integracja modelu z~aplikacją.
\end{itemize}

\section*{Deployment gotowego modelu na urządzenia końcowe}
Model będzie klasyfikował dane do późniejszego użycia. Model powinien być w stanie nadal się uczyć na nowych danych w oparciu o uczenie federacyjne.

\section*{Źródła}
\begin{itemize}
    \item LLM finetuning course: \url{https://maven.com/parlance-labs/fine-tuning}
    \item Huggingface NLP course: \url{https://huggingface.co/learn/nlp-course/en/chapter1/1}
\end{itemize}

\end{document}
