import numpy as np
import argparse
import subprocess
import difflib as diff
import os
import re
import json
import sys
import shutil
import csv
from typing import Optional, List, Tuple
from dataclasses import dataclass, field


@dataclass()
class Coupon:
    """
    Class representing data associated with a single coupon.
    """
    product_name: str
    new_price: Optional[str] = None
    old_price: Optional[str] = None
    percents: List[str] = field(default_factory=list)
    other_discounts: List[str] = field(default_factory=list)
    dates: Optional[str] = None


# Regex matches to different types of discounts
PERCENT_REGEX = r'\b(100|[1-9]?[0-9])\s?%\b'
PRICE_REGEX = r'\b\d+[.,]?\d*\b'

# Column names for the expected coupons
DISCOUNT_TEXT = 'discount_text'
PRODUCT_TEXT = 'product_text'
VALIDITY_TEXT = 'validity_text'

# Weights for each attribute of the coupon
NAME_WEIGHT = 0.3
PRICE_WEIGHT = 0.2
PERCENT_WEIGHT = 0.2
OTHER_DISCOUNT_WEIGHT = 0.2
VALIDITY_WEIGHT = 0.1

# Weights for the prices
NEW_PRICE_WEIGHT = 0.5
OLD_PRICE_WEIGHT = 0.5
LENGTH_PENALTY = 0.2
"""
This function will extract the discounts from the text of the coupon and return
them in a structured format. The discounts can be of different types: new price,
old price, percentage, or other discounts. The function will return the new and
old prices, the percentages, and the other discounts found in the text. Not all
discounts are required to be present in the text. The function will return None 
or an empty list if the discount is not found.
:param discount_text: The text of the coupon
:return: A tuple with the new price, old price, percentages, and other discounts
"""


def _get_discounts(
        discount_text: str) -> Tuple[str, str, List[str], List[str]]:
    new_price = None
    old_price = None
    percents = []
    other_discounts = []

    if discount_text is not None:
        discounts_found = 0
        if re.search(PRICE_REGEX, discount_text):
            prices = re.findall(PRICE_REGEX, discount_text)
            if len(prices) >= 2:
                prices = sorted([float(price) for price in prices])
                new_price = str(prices[0])
                old_price = str(prices[-1])
                discounts_found += 1

        if re.search(PERCENT_REGEX, discount_text):
            percents = re.findall(PERCENT_REGEX, discount_text)
            discounts_found += 1

        if discounts_found == 0:
            other_discounts = [discount_text]

    return new_price, old_price, percents, other_discounts


"""
This function will return a list of Coupon objects that represent the 
expected coupons. This function is used to benchmark the pipeline.
:param file_path: The path to the folder with the expected coupons in csv 
                format (like in the Murmuras datasets)
:return: A list of Coupon objects that represent the expected coupons
"""


def get_expected_coupons(file_path: Optional[str]) -> List[Coupon]:
    # No file path provided
    if file_path is None:
        return []

    expected_coupons = []

    for file_name in os.listdir(file_path):
        file_path_full = os.path.join(file_path, file_name)
        if os.path.isfile(file_path_full):
            with open(file_path_full, 'r') as file:
                reader = csv.DictReader(file)

                for row in reader:
                    new_price, old_price, percents, other_discounts = _get_discounts(
                        row[DISCOUNT_TEXT])

                    coupon = Coupon(product_name=row[PRODUCT_TEXT],
                                    new_price=new_price,
                                    old_price=old_price,
                                    percents=percents,
                                    other_discounts=other_discounts,
                                    dates=row[VALIDITY_TEXT])
                    expected_coupons.append(coupon)

    return expected_coupons


"""
This function will compare two lists of prices and return a float value that 
represents the similarity between them. The higher the value, the more similar 
the lists are. The lower the value, the more different the lists are. The lowest
and highest values of the lists are taken to be the old and new prices, 
respectively, and their similarity has more weight.The score takes into account 
the discrepancy in the number of prices between the two lists and punishes the 
pipeline accordingly. Each list will contain at most two prices: the new and old
prices. The lists can be empty or contain only one price.
:param generated_prices: The first list of prices to compare (generated by the 
                        pipeline)
:param expected_prices: The second list of prices to compare (expected)
:return: A float value that represents the similarity between the two lists
"""


def _compare_prices(generated_prices: list, expected_prices: list) -> float:
    # Convert the prices to floats and sort them; remove None values
    generated_prices = np.array(
        sorted(
            [float(price) for price in generated_prices if price is not None]))
    expected_prices = np.array(
        sorted(
            [float(price) for price in expected_prices if price is not None]))

    # Case 0: Both lists are either empty or contain only one price, so we can
    # compare them directly
    if len(expected_prices) == len(generated_prices) and (
            len(expected_prices) == 0 or len(expected_prices) == 1):
        if len(expected_prices) == 0:
            return 1.0

        return 1.0 if expected_prices[0] == generated_prices[0] else 0.0

    # Case 1: The generated list is empty, so it is completely different from
    # the expected list or vice versa
    if (len(generated_prices) == 0
            and len(expected_prices) > 0) or (len(generated_prices) > 0
                                              and len(expected_prices) == 0):
        return 0.0

    # Calculate the difference between the highest and lowest prices in
    # both lists
    new_prices = [generated_prices[0], expected_prices[0]]
    old_prices = [generated_prices[-1], expected_prices[-1]]

    new_price_ratio = 1.0 if new_prices[0] == new_prices[1] else 0.0
    old_price_ratio = 1.0 if old_prices[0] == old_prices[1] else 0.0

    coupon_difference = (new_price_ratio * NEW_PRICE_WEIGHT) + (
        old_price_ratio * OLD_PRICE_WEIGHT)

    # Case 2: Both lists have more than one price, so we can compare all
    # the prices
    if len(generated_prices) == len(expected_prices):
        return coupon_difference

    length_difference = abs(len(generated_prices) -
                            len(expected_prices)) / len(expected_prices)
    return max(0.0, coupon_difference - length_difference * LENGTH_PENALTY)


"""
This function will compare two coupons and return a float value that represents 
the similarity between the two coupons. The higher the value, the more similar 
the coupons are. The lower the value, the more different the coupons are. 
:param coupon_1, coupon_2: The first and second coupons to compare
:return: A float value that represents the similarity between the two coupons
"""


def compare_coupons(coupon_1: Optional[Coupon],
                    coupon_2: Optional[Coupon]) -> float:
    if coupon_1 is None or coupon_2 is None:
        return 0.0
    """
    product_name: str
    prices: List[str] = field(default_factory=list)
    percents: List[str] = field(default_factory=list)
    other_discounts: List[str] = field(default_factory=list)
    dates: List[str] = field(default_factory=list)
    """

    name_ratio = diff.SequenceMatcher(a=coupon_1.product_name,
                                      b=coupon_2.product_name).ratio()
    prices_ratio = _compare_prices([coupon_1.new_price, coupon_1.old_price],
                                   [coupon_2.new_price, coupon_2.old_price])

    percents_1 = sorted([str(percent) for percent in coupon_1.percents])
    percents_2 = sorted([str(percent) for percent in coupon_2.percents])
    percents_ratio = diff.SequenceMatcher(
        a=percents_1,
        b=percents_2).ratio() - 0.2 * abs(len(percents_1) - len(percents_2))

    discounts_1 = sorted(
        [str(discount) for discount in coupon_1.other_discounts])
    discounts_2 = sorted(
        [str(discount) for discount in coupon_2.other_discounts])
    other_discopunts_ratio = diff.SequenceMatcher(
        a=discounts_1, b=discounts_2).ratio(
        ) - 0.2 * abs(len(discounts_1) - len(discounts_2))

    dates_1 = sorted([str(date) for date in coupon_1.dates])
    dates_2 = sorted([str(date) for date in coupon_2.dates])
    dates_ratio = diff.SequenceMatcher(
        a=dates_1, b=dates_2).ratio() - 0.2 * abs(len(dates_1) - len(dates_2))

    return (name_ratio * NAME_WEIGHT) + (prices_ratio * PRICE_WEIGHT) + (
        percents_ratio * PERCENT_WEIGHT) + (
            other_discopunts_ratio * OTHER_DISCOUNT_WEIGHT) + (dates_ratio *
                                                               VALIDITY_WEIGHT)


"""
This function will judge the pipeline by comparing the expected coupons with the
generated ones. The function will return a tuple with the average similarity
between the coupons and the number of lonely coupons. The average similarity is
calculated by comparing each expected coupon with the most similar generated
coupon. The number of lonely coupons is the number of expected coupons that
could not be matched with any generated coupon and vice versa. 
:param expected_coupons: A list of Coupon objects that represent the
                        expected coupons
:param generated_coupons: A list of Coupon objects that represent the
                        generated coupons
:return: A tuple with the average similarity between the coupons and the number
        of lonely coupons
"""


def judge_pipeline(expected_coupons: List[Coupon],
                   generated_coupons: List[Coupon]) -> tuple[float, int]:
    generated_coupons = dict(
        (i, coupon) for i, coupon in enumerate(generated_coupons))
    lonely_coupons: int = 0
    similarities: List[float] = []

    for coupon in expected_coupons:
        max_similarity = 0.0
        max_coupon: int = -1

        for i, generated_coupon in generated_coupons.items():
            similarity = compare_coupons(coupon, generated_coupon)
            if similarity > max_similarity:
                max_similarity = similarity
                max_coupon = i

        if max_coupon == -1:
            lonely_coupons += 1
            continue

        del generated_coupons[max_coupon]
        similarities.append(max_similarity)

    if len(generated_coupons) > 0:
        lonely_coupons += len(generated_coupons)

    similarities.extend([0.0] * lonely_coupons)

    return (np.mean(similarities) if len(similarities) > 0 else 0.0,
            lonely_coupons)


"""
This function will run the pipeline with the input data and return the
generated coupons. The function will return None if the pipeline fails to run. 
The result of the pipeline must be written to a file called output.json.
:param pipeline_command: The command to run the pipeline
:param input_folder: The path to the folder with the input data
:return: A list of Coupon objects that represent the generated coupons
        or None if the pipeline fails to run
"""


def run_pipeline(pipeline_command: str,
                 input_folder: str) -> Optional[List[Coupon]]:
    pipeline_command = pipeline_command + " > output.json"

    try:
        subprocess.run(pipeline_command, shell=True, check=True)

        # The pipeline must write the output to a file called output.json
        proto_coupons = []
        with open("output.json", "r") as file:
            coupons = json.load(file)

        for coupon in coupons:
            proto_coupons.append(
                Coupon(product_name=coupon["product_name"],
                       new_price=coupon["new_price"],
                       old_price=coupon["old_price"],
                       percents=coupon["percents"],
                       other_discounts=coupon["other_discounts"],
                       dates=coupon["dates"]))
        return proto_coupons

    except subprocess.CalledProcessError as e:
        print(f"Error running the pipeline: {e.stderr}")
        return None


"""
This function will validate the format of the csv file that contains the
expected coupons. The file must contain the headers defined below. 
:param fieldnames: The headers of the csv file
:return: True if the file format is valid, False otherwise
"""


def _validate_output_file_format(fieldnames: list) -> bool:
    required_headers = [
        "product_text", "discount_text", "discount_details", "validity_text"
    ]
    return all(header in fieldnames for header in required_headers)


"""
This function will validate the format of the csv file that contains the
input data. The file must contain the headers defined below.
:param fieldnames: The headers of the csv file
:return: True if the file format is valid, False otherwise
"""


def _validate_input_file_format(fieldnames: list) -> bool:
    required_headers = [
        "view_depth", "text", "description", "class_name", "application_name"
    ]
    return all(header in fieldnames for header in required_headers)


"""
This function will validate the input and output folders. The input folder must
contain csv files with the format defined in the _validate_input_file_format
function. The output folder must contain csv files with the format defined in
the _validate_output_file_format function.
:param input_folder: The path to the folder with the input data
:param output_folder: The path to the folder with the expected coupons
:return: True if the folders are valid, False otherwise
"""


def validate_folders(input_folder: str, output_folder: str) -> bool:
    if not os.path.isdir(input_folder):
        raise NotADirectoryError(
            f"The input path {input_folder} is not a directory.")
    if not os.path.isdir(output_folder):
        raise NotADirectoryError(
            f"The output path {output_folder} is not a directory.")

    # Validate the output folder
    for file_name in os.listdir(output_folder):
        file_name_full = os.path.join(output_folder, file_name)
        if not os.path.isfile(file_name_full):
            raise NotADirectoryError(
                f"The output path {output_folder} is not a directory.")

        if not file_name.endswith('.csv'):
            raise ValueError(f"The file {file_name} is not a CSV file.")

        with open(file_name_full, 'r') as file:
            reader = csv.DictReader(file)
            if reader.fieldnames is None or not _validate_output_file_format(
                    list(reader.fieldnames)):
                raise ValueError(
                    f"The file {file_name} has an invalid format.")

    # Validate the input folder
    for file_name in os.listdir(input_folder):
        file_name_full = os.path.join(input_folder, file_name)
        if not os.path.isfile(file_name_full):
            raise NotADirectoryError(
                f"The input path {input_folder} is not a directory.")

        if not file_name.endswith('.csv'):
            raise ValueError(f"The file {file_name} is not a CSV file.")

        with open(file_name_full, 'r') as file:
            reader = csv.DictReader(file)
            if reader.fieldnames is None or not _validate_input_file_format(
                    list(reader.fieldnames)):
                raise ValueError(
                    f"The file {file_name} has an invalid format.")

    return True


"""
This function will get the default datasets from Google Drive and return the
paths to the input and expected folders. The function will create the folders
if they do not exist. If the folders already exist, the function will delete the
files inside them and replace them with the default datasets.
:return: A tuple with the paths to the input and expected folders
"""


def get_default_datasets() -> Tuple[str, str]:
    # Default paths to the input and expected folders
    input_folder = os.path.join(os.getcwd(), "input")
    expected_folder = os.path.join(os.getcwd(), "expected")

    # Create the folders; if they already exist, delete the files inside them
    for folder in [input_folder, expected_folder]:
        if not os.path.exists(folder):
            os.makedirs(folder)
        else:
            for file in os.listdir(folder):
                os.remove(os.path.join(folder, file))

    # Get the default datasets from google drive
    tools_path = os.path.abspath(
        os.path.join(os.path.dirname(__file__), '../../', 'tools'))
    sys.path.append(tools_path)
    script_path = os.path.join(tools_path, 'data_load.py')

    import data_load

    try:
        print("Running the data_load.py script to get the default datasets...")
        subprocess.run(['python3', script_path, 'coupons_1'], check=True)
    except subprocess.CalledProcessError as e:
        print(f"Error occurred while running the script: {e}")
    except FileNotFoundError:
        print(
            "The data_load.py file was not found. Ensure the path is correct.")

    # Get the path to the datasets folder
    datasets_path = os.path.abspath(
        os.path.join(os.path.dirname(__file__), '../../',
                     'datasets/coupons_1'))

    # Copy the files from the datasets folder to the input and expected folders
    for root, dirs, files in os.walk(datasets_path):
        for file in files:
            # One of the files has a typo in the name hence the check
            if "coupons" in file.lower() or "cupons" in file.lower():
                target = os.path.join(expected_folder, file)
            elif "content_generic" in file.lower():
                target = os.path.join(input_folder, file)
            else:
                continue

            source = os.path.join(root, file)

            shutil.copy(source, target)

    return input_folder, expected_folder


if __name__ == '__main__':
    # Parse the input arguments and check if the input and output paths are valid
    parser = argparse.ArgumentParser(description='Benchmarking script')
    parser.add_argument('-i',
                        '--input',
                        type=str,
                        required=False,
                        help='Path to the folder with the input data')
    parser.add_argument('-e',
                        '--expected',
                        type=str,
                        required=False,
                        help='Path to the folder with the expected coupons')
    parser.add_argument(
        '-p',
        '--pipeline',
        type=str,
        required=True,
        help=
        'Command to run the pipeline (e.g., ./run_pipeline --data <input_path>)'
    )
    args = parser.parse_args()

    # If either the input or expected folders are not provided, get the default
    # datasets
    if args.input is None or args.expected is None:
        args.input, args.expected = get_default_datasets()

    if not validate_folders(args.input, args.expected):
        raise ValueError("The input and expected folders are not valid.")

    # Get the expected coupons
    expected_coupons: List[Coupon] = get_expected_coupons(args.expected)
    generated_coupons: List[Coupon] = run_pipeline(args.pipeline, args.input)

    similarity, lonely_coupons = judge_pipeline(expected_coupons,
                                                generated_coupons)

    percent_similarity = round(similarity * 100, 3)
    print(f"Average similarity between the coupons: {percent_similarity}%")
    print(f"Number of lonely coupons: {lonely_coupons}")

    # For each lonely coupon, we subtract 0.1% from the similarity score
    # to penalize the pipeline
    final_score = max(percent_similarity, 0)
    print(f"Final score: {final_score}%")
