{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up everything\n",
    "I am using [this](https://spacy.io/api/architectures#HashEmbedCNN) architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /home/nawi/.local/lib/python3.10/site-packages (3.8.4)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (2.2.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (59.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/nawi/.local/lib/python3.10/site-packages (from spacy) (2.7.1)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/nawi/.local/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/nawi/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/nawi/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/nawi/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/nawi/.local/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /home/nawi/.local/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/nawi/.local/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/nawi/.local/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/nawi/.local/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/nawi/.local/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/nawi/.local/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /home/nawi/.local/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/nawi/.local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/nawi/.local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: wrapt in /home/nawi/.local/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/nawi/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
      "install the spacy-transformers package and re-run this command. The config\n",
      "generated now does not use transformers.\u001b[0m\n",
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: de\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy\n",
    "!spacy init config config.cfg --lang de --pipeline ner \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to edit the config so that it works properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file updated successfully!\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.cfg')\n",
    "\n",
    "config['paths']['train'] = 'output_data.spacy'\n",
    "\n",
    "config['nlp']['lang'] = 'de'\n",
    "config['nlp']['pipeline'] = '[\"ner\"]'  \n",
    "\n",
    "# config['components']['ner'] = 'factory = \"ner\"'\n",
    "\n",
    "# config.set('components', 'ner.model', '@architectures = \"spacy.TFMDNN.v2\"')  \n",
    "# config.set('components.ner.model', 'hidden_width', '128')\n",
    "# config.set('components.ner.model', 'maxout_pieces', '3')\n",
    "# config.set('components.ner.model', 'tok2vec', '{\"@architectures\": \"spacy.Tok2Vec.v2\", \"width\": 96, \"depth\": 4}')\n",
    "\n",
    "# config.set('training', 'optimizer', '{\"@optimizers\": \"Adam.v1\", \"learn_rate\": 0.001, \"beta1\": 0.9, \"beta2\": 0.999, \"eps\": 1e-08}')\n",
    "\n",
    "with open('config.cfg', 'w') as configfile:\n",
    "    config.write(configfile)\n",
    "\n",
    "print(\"Config file updated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import configparser\n",
    "\n",
    "# config = configparser.ConfigParser()\n",
    "# config.read(\"config.cfg\")\n",
    "\n",
    "# # Update the tok2vec model architecture to use HashEmbedCNN.v2\n",
    "# config['components.tok2vec.model'] = {\n",
    "#     '@architectures': 'spacy.Tok2Vec.v2',\n",
    "#     'embed': {\n",
    "#         '@architectures': 'spacy.HashEmbedCNN.v2',\n",
    "#         'width': 96,\n",
    "#         'depth': 1,\n",
    "#         'embed_size': 2000,\n",
    "#         'window_size': 1,\n",
    "#         'maxout_pieces': 3,\n",
    "#         'subword_features': True,\n",
    "#         'pretrained_vectors': False\n",
    "#     },\n",
    "#     'encode': {\n",
    "#         '@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
    "#         'width': 96,\n",
    "#         'depth': 1, # here we can specify the depth of CNN layers\n",
    "#         'window_size': 1,\n",
    "#         'maxout_pieces': 3\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# with open('config.cfg', 'w') as configfile:\n",
    "#     config.write(configfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to use the spancat method to allow for overlapping spans, ie, when a text has multiple of the same entity assigned to it. For example text=\"Google, Apple and Microsoft ale huge companies\" entities = [{start=..., end..., label='company_name'}, {start=..., end..., label='company_name'}, {start=..., end..., label='company_name'}]. This allows us to handle this situation and transform the data into a .spacy format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training.example import Example\n",
    "from spacy.language import Language\n",
    "from spacy.pipeline import SpanCategorizer # to handle repeated entities in the text\n",
    "\n",
    "with open(\"output.json\", \"r\") as file:  # load data for training\n",
    "    data = json.load(file)\n",
    "\n",
    "nlp = spacy.blank(\"de\")\n",
    "\n",
    "@Language.factory('span_cate')\n",
    "def create_span_categorizer(nlp, name):\n",
    "    return SpanCategorizer(nlp.vocab, model=\"sc\", suggester=None)\n",
    "\n",
    "if 'span_cate' in nlp.pipe_names:\n",
    "    nlp.remove_pipe('span_cate')\n",
    "    nlp.add_pipe('span_cate', last=True)\n",
    "\n",
    "doc_bin = DocBin()\n",
    "\n",
    "for entry in data:\n",
    "    text = entry[\"text\"]\n",
    "    entities = entry[\"entities\"]\n",
    "    doc = nlp.make_doc(text)\n",
    "\n",
    "    spans = []\n",
    "    for ent in entities:\n",
    "        start = ent[\"start\"]\n",
    "        end = ent[\"end\"]\n",
    "        label = ent[\"label\"]\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is not None:\n",
    "            spans.append(span)\n",
    "    \n",
    "    doc.spans[\"sc\"] = spans\n",
    "    doc_bin.add(doc)\n",
    "\n",
    "doc_bin.to_disk(\"output_data.spacy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting de-core-news-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download de_core_news_sm # download the german model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00      0.00    0.00    0.00    0.00    0.00\n",
      " 34     200          0.00      0.00    0.00    0.00    0.00    0.00\n",
      " 75     400          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "127     600          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "192     800          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "272    1000          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "372    1200          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "472    1400          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "627    1600          0.00      0.00    0.00    0.00    0.00    0.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n"
     ]
    }
   ],
   "source": [
    "# train the model with the config file we created above and the data we prepared\n",
    "# the output directory is ./output\n",
    "# the training data is ./output_data.spacy\n",
    "!python3 -m spacy train config.cfg --output ./output --paths.train output_data.spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities detected:\n"
     ]
    }
   ],
   "source": [
    "model_path = 'output/model-last'  # path to the model\n",
    "nlp = spacy.load(model_path)\n",
    "\n",
    "example_text = \"UVP 19.99 14.99 UVP GORDON'S London Dry Gin je 0,7 I UVP 1.49 1.19 UVP COCA-COLA Classic je 0,5 I UVP 3.99 3.59 UVP LAYS Chips je 150 g 2.49 Super Angebot LAYS Chips Knabberbox je 100 g Sparen auf ausgewählte Produkte ab 06.08. bis 07.09. Sonderaktionen für Mitglieder!\"\n",
    "\n",
    "doc = nlp(example_text)\n",
    "\n",
    "print(\"Entities detected:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} ({ent.label_})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions and challenges\n",
    "Challenges encountered:\n",
    "1. Creating the config was much more challenging than I anticipated as it required a lot of fiddling, debugging, understanding the functions, how they interact, etc. The tools provided by spacy were not that helpful so this was a pain. \n",
    "2. Converting the data we already have to the format that spacy requires is also tedious and I encountered a lot of problems, such as repeating entities, etc. This is quite annoying to deal with. \n",
    "\n",
    "Conclusion: Yes, I guess you can train a 1D CNN to do this since spacy uses a CNN under the hood, provided that you have a sufficient amount of data and you convert it into the format spacy likes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
