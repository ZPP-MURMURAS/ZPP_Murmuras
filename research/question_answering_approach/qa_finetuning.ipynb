{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# QA finetuning\n",
    "Notebook demonstrating fine-tuning bert model for qa task"
   ],
   "id": "c2bf7203b78a6b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:27:34.312988Z",
     "start_time": "2024-11-26T10:27:32.274988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import transformers\n",
    "from sympy import field\n",
    "from transformers import BertForQuestionAnswering, AutoTokenizer"
   ],
   "id": "4ceb2e7f270d79d9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/murmuras/ZPP_Murmuras/research/question_answering_approach/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:27:36.570216Z",
     "start_time": "2024-11-26T10:27:35.810306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ],
   "id": "de7e743a6aae59eb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Running on SQuAD [1] dataset",
   "id": "24a5a90b889ff688"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:28:28.494642Z",
     "start_time": "2024-11-26T10:28:21.636636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"squad\")"
   ],
   "id": "8ab231599b213d54",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:28:29.699330Z",
     "start_time": "2024-11-26T10:28:29.695082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_length = 384\n",
    "stride = 128\n",
    "\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ],
   "id": "fdb7d88bcff72be6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:30:33.360432Z",
     "start_time": "2024-11-26T10:30:33.074168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_datasets[\"train\"] = raw_datasets[\"train\"].select(range(1000))\n",
    "train_dataset = raw_datasets[\"train\"].map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")\n",
    "len(raw_datasets[\"train\"]), len(train_dataset)"
   ],
   "id": "c3f802c0422d2b2e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 3721.27 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 1032)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:30:41.142128Z",
     "start_time": "2024-11-26T10:30:41.138909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ],
   "id": "cdfa24f50210a143",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:30:57.219383Z",
     "start_time": "2024-11-26T10:30:57.075930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_datasets[\"validation\"] = raw_datasets[\"validation\"].select(range(200))\n",
    "validation_dataset = raw_datasets[\"validation\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
    ")\n",
    "len(raw_datasets[\"validation\"]), len(validation_dataset)"
   ],
   "id": "cfb5e41811323cd2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 1509.46 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:06:10.144992Z",
     "start_time": "2024-11-26T11:06:10.137276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "eval_set_for_model = validation_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "eval_set_for_model.set_format(\"torch\")\n",
    "\n",
    "batch = {k: eval_set_for_model[k] for k in eval_set_for_model.column_names}\n",
    "batch"
   ],
   "id": "b582b6c7130e09b2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2029, 5088,  ...,    0,    0,    0],\n",
       "         [ 101, 2029, 5088,  ...,    0,    0,    0],\n",
       "         [ 101, 2073, 2106,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 2029, 3792,  ...,    0,    0,    0],\n",
       "         [ 101, 2129, 2116,  ...,    0,    0,    0],\n",
       "         [ 101, 1999, 2054,  ...,    0,    0,    0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:31:38.391363Z",
     "start_time": "2024-11-26T10:31:37.247896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"squad\")\n",
    "\n",
    "n_best = 20\n",
    "max_answer_length = 30\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ],
   "id": "361a8fadc81fb2aa",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:35:25.713777Z",
     "start_time": "2024-11-26T10:32:14.763421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**batch)"
   ],
   "id": "5907680a0d53fcaa",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:35:25.741955Z",
     "start_time": "2024-11-26T10:35:25.722713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_logits = outputs.start_logits.cpu().numpy()\n",
    "end_logits = outputs.end_logits.cpu().numpy()"
   ],
   "id": "cbed834b46e50f27",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:37:23.853428Z",
     "start_time": "2024-11-26T10:37:23.581334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import collections\n",
    "\n",
    "example_to_features = collections.defaultdict(list)\n",
    "for idx, feature in enumerate(validation_dataset):\n",
    "    example_to_features[feature[\"example_id\"]].append(idx)"
   ],
   "id": "8236d94378842e85",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:39:04.700335Z",
     "start_time": "2024-11-26T10:38:49.251505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "n_best = 20\n",
    "max_answer_length = 30\n",
    "predicted_answers = []\n",
    "\n",
    "for example in raw_datasets[\"validation\"]:\n",
    "    example_id = example[\"id\"]\n",
    "    context = example[\"context\"]\n",
    "    answers = []\n",
    "\n",
    "    for feature_index in example_to_features[example_id]:\n",
    "        start_logit = start_logits[feature_index]\n",
    "        end_logit = end_logits[feature_index]\n",
    "        offsets = validation_dataset[\"offset_mapping\"][feature_index]\n",
    "\n",
    "        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # Skip answers that are not fully in the context\n",
    "                if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                    continue\n",
    "                # Skip answers with a length that is either < 0 or > max_answer_length.\n",
    "                if (\n",
    "                    end_index < start_index\n",
    "                    or end_index - start_index + 1 > max_answer_length\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                answers.append(\n",
    "                    {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "    predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"]})"
   ],
   "id": "5c5a8860fe7de4dc",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:39:38.840502Z",
     "start_time": "2024-11-26T10:39:38.823277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "theoretical_answers = [\n",
    "    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in raw_datasets[\"validation\"]\n",
    "]"
   ],
   "id": "daeaab50cac0e6cd",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:39:49.562207Z",
     "start_time": "2024-11-26T10:39:49.560147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(predicted_answers[0])\n",
    "print(theoretical_answers[0])"
   ],
   "id": "4089826d0736d42b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '56be4db0acb8001400a502ec', 'prediction_text': 'Denver Broncos'}\n",
      "{'id': '56be4db0acb8001400a502ec', 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}}\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:40:04.215988Z",
     "start_time": "2024-11-26T10:40:04.185088Z"
    }
   },
   "cell_type": "code",
   "source": "metric.compute(predictions=predicted_answers, references=theoretical_answers)",
   "id": "a52f4fe7d199b023",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 95.5, 'f1': 97.58095238095238}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning on coupon data\n",
    "### dataset preparation"
   ],
   "id": "8bd22e3a1d58f9ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T12:24:21.934914Z",
     "start_time": "2024-11-26T12:24:21.525565Z"
    }
   },
   "cell_type": "code",
   "source": "import json, pandas",
   "id": "864865a3765996c8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T12:24:22.419033Z",
     "start_time": "2024-11-26T12:24:22.409798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "USED_COLUMNS = [\"Text\", \"X 1\", \"Y 1\", \"View Class Name\", \"View Depth\"]\n",
    "\n",
    "with open(\"ds/18929485529_expected.json\", \"r\") as f:\n",
    "    resps = json.load(f)\n",
    "    \n",
    "for x in resps[\"coupons\"]:\n",
    "    x.pop(\"discount\")\n",
    "    x.pop(\"validity\")\n",
    "    \n",
    "frame = pandas.read_csv(\"ds/18929485529.csv\")\n",
    "# currently hardcoded\n",
    "sample_indices = [slice(2, 7), slice(7, 12), slice(49, 54), slice(78, 83), slice(92, 97), slice(97, 102)]\n",
    "\n",
    "frame = frame[USED_COLUMNS]\n",
    "contexts = [frame[ind].to_csv() for ind in sample_indices]\n",
    "\n",
    "QUESTIONS = {\n",
    "    \"old_price\": \"What is the old price of product?\",\n",
    "    \"new_price\": \"What is the new price of product?\",\n",
    "    \"product_name\": \"What is the name of the discounted product?\"\n",
    "}"
   ],
   "id": "d5d85a76ed13a712",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Converting answers to locations in contexts",
   "id": "726c8751920d2be0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T12:25:27.381474Z",
     "start_time": "2024-11-26T12:25:25.245808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "answers_converted = {k: [] for k in QUESTIONS}\n",
    "answers = {k: [e[k] for e in resps['coupons']] for k in QUESTIONS}\n",
    "\n",
    "tokenized = tokenizer(contexts, return_offsets_mapping=True, add_special_tokens=False)\n",
    "\n",
    "for i, (ctx, tokenized_ctx, ctx_offsets) in enumerate(zip(contexts, tokenized[\"input_ids\"], tokenized[\"offset_mapping\"])):\n",
    "    decoded_tokens = tokenizer.convert_ids_to_tokens(tokenized_ctx)\n",
    "    token_offsets = []\n",
    "    for token, (start, end) in zip(decoded_tokens, ctx_offsets):\n",
    "        token_offsets.append({\"token\": token, \"start\": start, \"end\": end, \"text\": ctx[start:end]})\n",
    "\n",
    "    # Print tokens alongside their positions and text\n",
    "    \"\"\"for t in token_offsets:\n",
    "        print(f\"Token: {t['token']}, Start: {t['start']}, End: {t['end']}, Text: '{t['text']}'\")\"\"\"\n",
    "        \n",
    "    for q in answers:\n",
    "        answer = answers[q][i]\n",
    "        start_char = ctx.find(answer)\n",
    "        end_char = start_char + len(answer)\n",
    "        \n",
    "        # Locate the corresponding tokens\n",
    "        start_token_idx = None\n",
    "        end_token_idx = None\n",
    "        \n",
    "        for idx, (start, end) in enumerate(ctx_offsets):\n",
    "            if start <= start_char < end:\n",
    "                start_token_idx = idx\n",
    "            if start < end_char <= end:\n",
    "                end_token_idx = idx\n",
    "                break\n",
    "        \n",
    "        print(f\"Answer: '{answer}'\")\n",
    "        print(f\"Character-level Start: {start_char}, End: {end_char}\")\n",
    "        print(f\"Token-level Start: {start_token_idx}, End: {end_token_idx}\")\n",
    "        \n",
    "        answers_converted[q].append([start_token_idx, end_token_idx])"
   ],
   "id": "63a92a7318ea2c23",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szymon/murmuras/ZPP_Murmuras/research/question_answering_approach/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: '14.99'\n",
      "Character-level Start: 47, End: 52\n",
      "Token-level Start: 19, End: 21\n",
      "Answer: '9.99'\n",
      "Character-level Start: 90, End: 94\n",
      "Token-level Start: 39, End: 41\n",
      "Answer: 'JOHNNIE WALKER Red Label Blended Scotch'\n",
      "Character-level Start: 172, End: 211\n",
      "Token-level Start: 78, End: 83\n",
      "Answer: '0.99'\n",
      "Character-level Start: 47, End: 51\n",
      "Token-level Start: 19, End: 21\n",
      "Answer: '0.75'\n",
      "Character-level Start: 89, End: 93\n",
      "Token-level Start: 40, End: 42\n",
      "Answer: 'SAN MIGUEL Especial'\n",
      "Character-level Start: 173, End: 192\n",
      "Token-level Start: 81, End: 85\n",
      "Answer: '2.99'\n",
      "Character-level Start: 48, End: 52\n",
      "Token-level Start: 19, End: 21\n",
      "Answer: '2.79'\n",
      "Character-level Start: 92, End: 96\n",
      "Token-level Start: 40, End: 42\n",
      "Answer: 'FELIX Knabber Mix'\n",
      "Character-level Start: 178, End: 195\n",
      "Token-level Start: 79, End: 83\n",
      "Answer: '8.99'\n",
      "Character-level Start: 48, End: 52\n",
      "Token-level Start: 19, End: 21\n",
      "Answer: '5.85'\n",
      "Character-level Start: 92, End: 96\n",
      "Token-level Start: 40, End: 42\n",
      "Answer: 'CHANTRÃ‰ Weinbrand'\n",
      "Character-level Start: 178, End: 195\n",
      "Token-level Start: 80, End: 84\n",
      "Answer: '2.79'\n",
      "Character-level Start: 44, End: 48\n",
      "Token-level Start: 17, End: 19\n",
      "Answer: '2.49'\n",
      "Character-level Start: 88, End: 92\n",
      "Token-level Start: 38, End: 40\n",
      "Answer: 'PENNY Gouda-Scheiben'\n",
      "Character-level Start: 182, End: 202\n",
      "Token-level Start: 80, End: 86\n",
      "Answer: '1.09'\n",
      "Character-level Start: 44, End: 48\n",
      "Token-level Start: 17, End: 19\n",
      "Answer: '0.69'\n",
      "Character-level Start: 88, End: 92\n",
      "Token-level Start: 38, End: 40\n",
      "Answer: 'KINDER Ãœberraschungs-Ei'\n",
      "Character-level Start: 184, End: 207\n",
      "Token-level Start: 81, End: 90\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create JSON dataset and convert it to datasets library object",
   "id": "d3b29560324da58b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T12:25:32.090299Z",
     "start_time": "2024-11-26T12:25:31.282150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "as_json = [{\n",
    "   \"id\": ci * len(QUESTIONS) + qi,\n",
    "   \"title\":\"example_title\",\n",
    "   \"context\": ctx,\n",
    "   \"question\": QUESTIONS[q_key],\n",
    "   \"answers\":{\n",
    "      \"text\":[\n",
    "         answers[q_key][ci]\n",
    "      ],\n",
    "      \"answer_start\":[\n",
    "         answers_converted[q_key][ci][0]\n",
    "      ]\n",
    "   }\n",
    "} for ci, ctx in enumerate(contexts) for qi, q_key in enumerate(QUESTIONS)]\n",
    "with open(\"ds.json\", \"w\") as f:\n",
    "    for entry in as_json:\n",
    "        json.dump(entry, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"ds.json\")\n",
    "dataset"
   ],
   "id": "340be9edd4481846",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 18 examples [00:00, 7358.43 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 18\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T12:25:36.118175Z",
     "start_time": "2024-11-26T12:25:35.913030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    questions = examples[\"question\"]\n",
    "    contexts = examples[\"context\"]\n",
    "    answers = examples[\"answers\"]\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    \n",
    "    for i, answer in enumerate(answers):\n",
    "        start_char = answer['answer_start'][0]\n",
    "        end_char = start_char + len(answer['text'][0])\n",
    "        \n",
    "        # Map start and end character positions to token indices\n",
    "        start_positions.append(inputs.char_to_token(i, start_char))\n",
    "        end_positions.append(inputs.char_to_token(i, end_char - 1))\n",
    "        \n",
    "        # Handling edge cases where the tokenizer may not capture the exact indices\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length - 1\n",
    "    \n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = dataset['train'].map(preprocess_function, batched=True)\n"
   ],
   "id": "4949bb6c6727f523",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 979.46 examples/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-26T12:26:10.208318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ],
   "id": "cc5c5be1e0a1f507",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/szymon/murmuras/ZPP_Murmuras/research/question_answering_approach/.venv/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_16351/2872322664.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Sources\n",
    "[1]: https://arxiv.org/abs/1606.05250"
   ],
   "id": "cc8c7e2fb6fc0304"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. https://arxiv.org/abs/1606.05250",
   "id": "7f3fc08ba6bc61b6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
