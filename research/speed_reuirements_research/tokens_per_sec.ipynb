{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "In this notebook I will estimate minimal number of tokens that our llama model will consume per second.<br/>\n",
    "The following calculations are made under optimistic assumption that we will parse only content from text fields."
   ],
   "id": "b9054c1adc463a7c"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-06T17:52:00.918064Z",
     "start_time": "2025-01-06T17:52:00.910435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import LlamaTokenizerFast\n",
    "from datetime import datetime"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T17:43:53.614490Z",
     "start_time": "2025-01-06T17:43:52.174538Z"
    }
   },
   "cell_type": "code",
   "source": "!python ../../tools/data_load.py coupons_1",
   "id": "f6001170a243caa1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/szymon/murmuras/ZPP_Murmuras/research/speed_reuirements_research/../../tools/data_load.py\", line 101, in <module>\r\n",
      "    children, parent, folder_names = create_fs_tree(service)\r\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/home/szymon/murmuras/ZPP_Murmuras/research/speed_reuirements_research/../../tools/data_load.py\", line 44, in create_fs_tree\r\n",
      "    .execute()\r\n",
      "     ^^^^^^^^^\r\n",
      "  File \"/home/szymon/murmuras/ZPP_Murmuras/.venv/lib/python3.12/site-packages/googleapiclient/_helpers.py\", line 130, in positional_wrapper\r\n",
      "    return wrapped(*args, **kwargs)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/home/szymon/murmuras/ZPP_Murmuras/.venv/lib/python3.12/site-packages/googleapiclient/http.py\", line 923, in execute\r\n",
      "    resp, content = _retry_request(\r\n",
      "                    ^^^^^^^^^^^^^^^\r\n",
      "  File \"/home/szymon/murmuras/ZPP_Murmuras/.venv/lib/python3.12/site-packages/googleapiclient/http.py\", line 191, in _retry_request\r\n",
      "    resp, content = http.request(uri, method, *args, **kwargs)\r\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/home/szymon/murmuras/ZPP_Murmuras/.venv/lib/python3.12/site-packages/google_auth_httplib2.py\", line 218, in request\r\n",
      "    response, content = self.http.request(\r\n",
      "                        ^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/home/szymon/murmuras/ZPP_Murmuras/.venv/lib/python3.12/site-packages/httplib2/__init__.py\", line 1581, in request\r\n",
      "    conn = self.connections[conn_key] = connection_type(\r\n",
      "                                        ^^^^^^^^^^^^^^^^\r\n",
      "  File \"/home/szymon/murmuras/ZPP_Murmuras/.venv/lib/python3.12/site-packages/httplib2/__init__.py\", line 1100, in __init__\r\n",
      "    context = _build_ssl_context(\r\n",
      "              ^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/home/szymon/murmuras/ZPP_Murmuras/.venv/lib/python3.12/site-packages/httplib2/__init__.py\", line 183, in _build_ssl_context\r\n",
      "    context.load_verify_locations(ca_certs)\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T17:44:00.362343Z",
     "start_time": "2025-01-06T17:44:00.192921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "frames = []\n",
    "DS_PATH = Path(\"../..\") / \"datasets\" / \"coupons_1\"\n",
    "PATHS = [\n",
    "    DS_PATH / \"lidl\" / \"Kopia test_data_2024_11_25_lidl_plus_content_generic_2024-12-05T07_39_49.726955559+01_00.csv\",\n",
    "    DS_PATH / \"dm\" / \"Kopia test_data_2024_03_07_dm_content_generic_2024-12-05T10_09_32.502568365+01_00.csv\",\n",
    "    DS_PATH / \"rewe\" / \"Kopia test_data_2024_03_07_rewe_content_generic_2024-12-05T10_30_59.948177782+01_00.csv\",\n",
    "    DS_PATH / \"rossmann\" / \"Kopia test_data_2024_03_07_rossmann_content_generic_2024-12-05T10_24_07.981399375+01_00.csv\"\n",
    "]\n",
    "\n",
    "for path in PATHS:\n",
    "    frames.append(pd.read_csv(path))"
   ],
   "id": "c40ea65da4e3cbf5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T18:00:20.304279Z",
     "start_time": "2025-01-06T18:00:18.414622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = LlamaTokenizerFast.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
    "TEXT_COL_NAME = \"text\"\n",
    "TIMESTAMP_COL_NAME = \"seen_timestamp\"\n",
    "\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.tokenize(text))\n",
    "\n",
    "tokens_cum = 0\n",
    "seconds_cum = 0\n",
    "\n",
    "for frame in frames:\n",
    "\n",
    "    texts = frame[TEXT_COL_NAME]\n",
    "    texts = texts[texts.notnull()]\n",
    "    total_tokens = texts.apply(count_tokens).sum()\n",
    "    times = frame[TIMESTAMP_COL_NAME]\n",
    "    times = times[times > 0]\n",
    "    time_start = datetime.fromtimestamp(times.min() // 1000)\n",
    "    time_end = datetime.fromtimestamp(times.max() // 1000)\n",
    "    total_seconds = (time_end - time_start).total_seconds()\n",
    "\n",
    "    print(total_tokens, total_seconds)\n",
    "    tokens_cum += total_tokens\n",
    "    seconds_cum += total_seconds\n",
    "\n",
    "print(f\"required min processing speed: {float(tokens_cum / seconds_cum)} tokens per second\")"
   ],
   "id": "e370b8e16b233c50",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \n",
      "The class this function is called from is 'LlamaTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11739 169.0\n",
      "15026 56.0\n",
      "23708 80.0\n",
      "14678 79.0\n",
      "required min processing speed: 169.6640625 tokens per second\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
